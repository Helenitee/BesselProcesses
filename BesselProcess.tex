\documentclass[openany]{book}
\usepackage[french]{babel}

\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amsthm} 
\usepackage{amsfonts}
\usepackage{aliascnt}
\usepackage{dsfont}
\usepackage{enumitem}
\usepackage{chngcntr}
\usepackage{xcolor}

\usepackage[
  colorlinks=true,
  linkcolor=blue,
  pdfborder={0 0 0},
  pdfpagemode=UseNone
  ]{hyperref}

  
\newtheoremstyle{deffont}% nom du style
  {\topsep}          % espace au-dessus
  {\topsep}          % espace en dessous
  {\upshape}         % style du corps (ici italique pour les théorèmes)
  {}                 % indentation
  {\bfseries}        % style du titre
  {}                % ponctuation après le titre
  { }                % espace après le titre
  {\thmname{#1}~\thmnumber{#2}\thmnote{~(#3)}}  % format du titre

\newtheoremstyle{thmfont}% nom du style
  {\topsep}          % espace au-dessus
  {\topsep}          % espace en dessous
  {\itshape}         % style du corps (ici italique pour les théorèmes)
  {}                 % indentation
  {\bfseries}        % style du titre
  {}                % ponctuation après le titre
  { }                % espace après le titre
  {\thmname{#1}~\thmnumber{#2}\thmnote{~(#3)}}  % format du titre

% pagestyle ==============================
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{titlesec} % 

\geometry{
  a4paper,
  left=3.5cm,
  right=3.5cm,
  top=3cm,
  bottom=3cm,
  twoside
}

% newcomands ==============================
\newcommand{\F}{\mathscr{F}}
\newcommand{\N}{\mathscr{N}}
\newcommand{\carE}{\mathscr{E}}
\renewcommand{\P}{\mathds{P}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
%\newcommand{\1}{\mathbb{1}}
\setlist[enumerate,1]{label=\textit{\roman*}.}

% newtheorem ==============================
\theoremstyle{thmfont}
\newtheorem{theorem}{Théorème}[chapter]
\providecommand*{\theoremautorefname}{Théorème}

\theoremstyle{deffont}
\newaliascnt{definition}{theorem}
\newtheorem{definition}[definition]{Définition}
\aliascntresetthe{definition}
\providecommand*{\definitionautorefname}{Définition}

\theoremstyle{thmfont}
\newaliascnt{prop}{theorem}
\newtheorem{prop}[prop]{Proposition}
\aliascntresetthe{prop}
\providecommand*{\propautorefname}{Proposition}

\theoremstyle{deffont}
\newtheorem*{remark}{Remarque}


% Mise en page ============================

\title{Cellules en itéraction singulière}
\author{Héléna Benet Burgaud}
% =========================================

\newcounter{thmsum}

\begin{document}

\pagenumbering{gobble}

\maketitle
\tableofcontents
\clearpage
\pagenumbering{arabic} % recommence à 1
\setcounter{page}{1}
\let\cleardoublepage\relax
\chapter{Rappels de probabilités et premières définitions}

Soit $(\Omega, \F, \P )$ un espace probabilisé et soit $(E, \carE)$ un espace mesurable. Dans ce travail, on prend $E = \R^d$ et $\carE$ sa tribu borélienne associée.

\begin{definition}[Processus stochastique] Un \textit{processus stochastique (continu)} est une famille de variables aléatoires définies sur un espace probabilisé. C'est à dire pour tout $t \in \R_+$ et $\omega \in \Omega$ la fonction 
 \begin{align*}
   X : (\R, \Omega) &\rightarrow \R \\
   (t, \omega) &\mapsto X_t(\omega)
 \end{align*} 
est une fonction mesurable. Cette fonction appliquée à un $\omega \in \Omega$ est appelée une \textit{trajectoire} de $X$.
\end{definition}

 Sauf indication contraire, on suppose que toutes les variables aléatoires considérées sont à trajectoires continues. 

\begin{definition}[Filtration] Une \textit{filtration} dans l'espace $(\Omega, \F, \P )$ est une suite de sous tribus de $\F$, indexées dans $\overline{\R} = \R \cup \{\infty\}$, croissantes par inclusion.\\
i.e. pour $s \leq t \leq \infty$,
$$\F_0 \subset \F_s \subset \F_t\subset \cdots \subset \F_\infty .$$

On parle de \textit{filtration naturelle} lorsque, pour chaque $t$, $F_t$ est la plus petite tribu telle les $X_s$, $s\leq t$ sont $F_t$-mesurables. i.e.
$$F_t := \sigma\{X_s, s\leq t\}$$

On introduit également la notion de \textit{filtration complète} ou
\textit{filtration canonique} qui, en plus d'être engendrée par tous les $X_s$, $s \leq t$, est engendrée par la famille des ensembles négligeables $\N$. i.e.
$$F^X_t := \sigma\{X_s\cup \N, s\leq t\}$$

\label{def:filtration}
\end{definition}

%Intuitivement, une filtration naturelle $\{F_t\}_{t\geq0}$ regroupe toute l'information qu'on connait depuis le moment $0$ jusqu'à $t$. D'où le fait que tous les $X_s$ avec $s \leq t$ soient $F_t$-mesurables.

\begin{definition}[Processus adapté] Un processus stochastique $\{X_s\}_{s\ge0}$ à valeurs dans l'espace mesurable $(E, \carE)$ est dit \textit{adapté} à la filtration $\{F_s\}_{s\geq0}$ si pour tout $t\geq0$, $X_t$ est $F_t$-mesurable.
\label{def:pr_adapte}
\end{definition}

\begin{definition}[Processus prévisible] Un processus stochastique est dit $\F_t$-\textit{prévisible} si pour tout $s < t$, $X_s$ est $\F_s$-mesurable.
\label{def:pr_previsible}
\end{definition}


\begin{definition}[Processus à accroissements indépendants]
  \label{def:pr_accr_indep} Un processus à \textit{accroissements indépendants} est un proceesus tel que, pour toute subdivision de $[0,t]$, la famille de variables aléatoires
    $$\{X_{t_1} - X_{t_0}, X_{t_2} - X_{t_1}, \cdots ,X_{t_n} - X_{t_{n-1}}\}$$
    est indépendante.
\end{definition}

{\color{red}
\begin{definition}[Processus à accroissements stationnaires]
        \label{def:pr_accr_sta}

\end{definition}
    
  point sur ``up to indistinguishability''.
}

\section{Variation quadratique et covariation}
% {\color{red} ``A major difference between standard integral calculus and stochastic calculus is the existence of quadratic variations and covariations'' -- George Lowther }

La \textit{variation quadratique} est un processus qui mesure les ``petites variations'' d'une v.a. au cours du temps. C'est une forme de dérivée au sens stochastique. En effet, même si un processus stochastique n'est pas dérivable au sens classique, on peut lui associer une variation quadratique. 

\begin{definition}[Covatiation et variation quadratique] On se donne une subdivision finie de $[0,t]$ :  $0 = t_0 < t_1 < \cdots < t_n = t$.\\
  Alors, la \textit{covariation}, appelée aussi \textit{crochet de covariation}, de $X$ et de $Y$ est le processus stochastique définit par :
  $$[X,Y]_t = \lim_{n\to \infty} \sum_{i = 1}^n(X_{t_i} - X_{t_{i-1}})(Y_{t_i} - Y_{t_{i-1}}).$$

 On peut définir de manière similaire la \textit{variation quadratique} :
 $$[X]_t = [X,X]_t = \lim_{n\to \infty} \sum_{i = 1}^n\|X_{t_i} - X_{t_{i-1}}\|^2.$$
\label{def:crochet}
\end{definition}

\begin{prop} Soit $X$ et $Y$ deux variables aléatoires définies dans le même espace probabilisé. Soit $[X,Y]$ leur crochet de covariation. Celui-ci vérifie les propertiés suivantes : 
  \begin{enumerate}
  \item Linéarité : Soit $\lambda, \mu \in \R$ et $Z$ une variable aléatoire. $$[\lambda X + \mu Y, Z]_t = \lambda[X,Z]_t + \mu[Y,Z]_t,$$
  \item Symétrie : $[X,Y]_t = [Y,X]_t$,
  \item Croissance : $\forall s\leq t$, $[X]_s \leq [X]_t$,
  \end{enumerate}
\end{prop}

\begin{definition}[Fonction à variation finie] Une fonction continue $a : \Omega \rightarrow \R$ est dite \textit{à variation finie} si $a(0) = 0$ et s'il existe une \textbf{mesure signée} $\mu$ sur $\mathcal B([0,t])$ tel que $a(t) = \mu([0,t]) = \mu_+([0,t]) - \mu_-([0,t])$ pour tout $t \geq 0$.
\label{def:fct_var_finie}
\end{definition}

\begin{remark}
  \begin{enumerate}
  \item La mesure $\mu$ est uniquement déterminée par la fonciton $a$.
  \item La condition ``$a(0)=0$'' n'est pas nécessaire mais nous l'utilisons premièrement parce qu'on travarillera avec des mouvements browniens stantards plus tard {\color{red}(cf ...)} et en plus cela nous facilite la tache. Mais ceci peut bien sûr se généraliser aux fonctions qui ne sont pas nulles en zéro.
  \item Comme $a(0) = 0$ et $a$ est continue, alors la mesure $\mu$ n'a pas d'\textit{atomes}, c'est à dire que tout singleton est de mesure nulle.
  \end{enumerate}
\end{remark}

\begin{definition}[Processus à variation finie]
  On dit d'un processus est \textit{à variation finie} (v.f) si ses trajectoires sont des des fonctions à variation finie.

  Si on se donne une subdivision finie de $[0,t]$ :  $0 = t_0 < t_1 < \cdots < t_n = t$, on peut définit un processus à variation finie comme la somme des incréments (en valeur absolue) en prenant la ``meilleure'' subdivision possible, i.e. celle qui maximise cette somme :
  $$ V_t(X) = \lim_{n \to \infty} \sum_{i=1}^n |X_{t_i} - X_{t_{i-1}}| < \infty$$
\end{definition}

Intuitivement, Processus à variation finie est un processus qui ``vibre'' de manière finie. Donc on n'aura pas de variation infinitessimale comme avec un mouvement brownien.

\begin{prop}
  \begin{enumerate}[nosep]
  \item Additivité : Soient $X$ et $Y$ des processus v.f. alors, $V(X+Y)$ l'est aussi; de plus, on a : $\forall t, \; V_t(X+Y) \leq V_t(X)+V_t(Y),$
  \item Multiplication externe : Soit $X$ un processus v.f. et $a$ une constante réelle, alors, $V(aX) = |a| V(X)$,
  \item Variation quadratique nulle : Soit $V(X)$ un processus v.f., alors,\\ $\forall t,\; [V(X)]_t=0$
  \item Tout processus croissant (resp. decroissant) est à variation finie.
  \end{enumerate}
\end{prop}

\begin{remark}
  Le crochet d'un processus est un v.f de part sa croissance.
\end{remark}

\section{Martingales, semimartingales et martingales locales}

\begin{definition}[$\F_t$-Martingale]
  Une \textit{martingale} est un processus $M$ satisfaisant :
  \begin{enumerate}[nosep]
    \item Adapté par rapport à la filtration $\F_t$,
    \item Intégrable : $\E(|M_t|) < \infty$,
    \item Tel que : $\forall t, \; \E(M_t|\F_s) = M_s$.
  \end{enumerate}
\end{definition}

La propriété \textit{iii.} nous dit que toute prévision du futur ($M_t$) sachant le passé ($F_s$) est égale au présent ($M_s$).

Les martingales sont des objets très utilisés en calcul stochastique mais finalement très restraints. C'est pourquoi on utilise les semimartingales :

\begin{definition}[Semimartingale] Une \textit{semimartingale} est un processus stochastique $X$ qui se décompose de manière unique comme une somme de trois processus : $X_t = X_0+ M_t + V_t$; où $X_0$ est $\F_0$-mesurable, $M$ est une martingale et $V$ un processus à variation finie.
\end{definition}

\section{Mouvement brownien}

\begin{definition}[Mouvement Brownien de variance $\sigma^2$] Un \textit{mouvement brownien} est un processus stochastique $(B_t)_{t>0}$ est :
  \begin{enumerate}
  \item à accroissements indépendants,\\
    i.e. pour toute subdivision finie de $[0,t]$ :  $0 = t_0 < t_1 < \cdots < t_n = t$, la famille des variables aléatoires
    $\{X_{t_1} - X_{t_0}, X_{t_2} - X_{t_1}, \cdots ,X_{t_n} - X_{t_{n-1}}\}$
    est indépendante,
  \item de trajectoires continues,
  \item tel que $B_s - B_t \sim \mathcal{N}(0,\sigma^2|s-t|)$.
  \end{enumerate}
\end{definition}

\begin{definition}[$\F_t$ mouvement brownien (de variance $\sigma^2$] Un processus $(B_t)_t$ est \textit{\( \mathcal{F}_t \)-mouvement brownien} s'il vérifie les propriétés suivantes :

  \begin{enumerate}
  \item Le processus est adapté à la filtration \( (\mathcal{F}_t) \).
  \item Les trajectoires de \( (B_t) \) sont continues p.s. ;
  \item Pour tout \( 0 \leq s < t \), \( B_t - B_s \) est indépendante de \( \mathcal{F}_s \) et suit une loi normale \( \mathcal{N}(0, \sigma^2|t - s|)\) ;
  \end{enumerate}

  Un \( \mathcal{F}_t \)-mouvement brownien \( (B_t) \) est dit \textit{standard} si, en plus des propriétés précédentes, il vérifie que pour tout \( t \geq 0 \), \(B_t \sim \mathcal{N}(0, t) \).
Autrement dit, \( B_t \) suit une loi normale centrée de variance \( t \), ce qui implique que :

\[
\mathbb{E}[B_t] = 0 \quad \text{et} \quad \text{Var}(B_t) = t.
\]
  \end{definition}

\section{Intégrale stochastique}  
\subsection{Intégrale de Lebesgue-Stieltjes}
\subsection{Intégrale d'Itō}
\subsection{Propriétés de l'intégrale stochastique}
{\color{red}
\begin{prop}
  Soit $H_s$ un processus prévisible et soit $M_s$ une martingale. Alors le processus définit par 
  $$\int_0^t H_s dM_s$$

  est une martingale.
\end{prop}
}

{\color{red}
\begin{theorem}[Isométrie d'Itō]
\end{theorem}

\begin{theorem}[Formule d'Itō]  
\end{theorem}
}

\chapter{Temps locaux}
\section{Construction d'un temps local}\label{sec:ConstrTempsLoc}

Pour un semimartingale $X$, son \textit{temps local} en un point $x$, $L_t^x$, est une mesure de la quantité de temps que $X$ passe au point $x$. La première approche, la plus intuitive est de compter tous les temps $s$ tel que $X_S = x$ :

\begin{equation}
  \label{eq:TmpsLocalDef1}
   L^x_t= \int_0^t1_{\{X_s=x\}}ds.
  \end{equation}

  Ceci dit, comme on intègre par rapport à la mesure de Lebesgue, $\{X_s = x\}$ est de mesure nulle, donc cette intégrale sera toujours nulle. Une alternative est d'utiliser un Dirac en $X_s - x$ au lieu de l'indicatrice dans \eqref{eq:TmpsLocalDef1}, de cette manière, nous n'avons plus la 


\begin{equation}
  \label{eq:TmpsLocalDef2}
  L^x_t= \int_0^t\delta(X_s-x)ds.
\end{equation}

Malheureusement, le dirac n'est pas une fonction mais une distribution, donc \eqref{eq:TmpsLocalDef2} n'est pas bien définie. Il est vrai que integrer par rapport à la mesure de Lebesgue est plus naturel puisqu'on voudrait à priori intégrer sur le temps, mais en intégrant par rapport à la mesure de Lebesgue, le terme stochastique ne se comportera pas comme on le souhaiterait; c'est pourquoi il est plus judicieux d'intégrer par rapport au crochet de $X$, qui, assure une bonne définition de l'intégrale stochastique. 
% Une solution possible est d'intégrer non pas par rapport à la mesure de Lebesgue, mais par rapport au crochet de $X_s$:
\begin{equation}
  \label{eq:TmpsLocalDef3}
  L^x_t= \int_0^t\delta(X_s-x)d[X]_s.
\end{equation}

Contrairement à $ds$, le crochet a du sens même lorsque l’on regarde des trajectoires très irrégulières. Dans le cas du mouvement brownien, intégrer par rapport à $d[B]_s$ ou $ds$ est équivalent, mais cette nouvelle définition a l'avantage d'avoir du sens dans des cadres plus généraux.
Le seul problème maintenant est que le Dirac n'est toujours pas une fonction. Ainsi on peut l'approximer par $\lim_{\varepsilon\to 0}  1_{\{x - \varepsilon < B_s < x + \varepsilon\}}$ et ainsi obtenir une définition rigoureuse du \textit{temps local}.

\begin{definition}[Temps local] Un \textit{temps local} associé à une semimartingale $X$ est un processus stochastique caractérisé par :
\begin{equation*}
    L_t^x = \lim_{\varepsilon \to 0} \frac{1}{2\varepsilon} \int_0^t 1_{\{x - \varepsilon < X_s < x + \varepsilon\}} \, d[X]_s
\end{equation*}
\end{definition}

\begin{remark}
  Les temps locaux sont des processus \textit{continus}, \textit{positifs}, \textit{croissants} et à \textit{variation finie}.
\end{remark}


\begin{prop}[Propriété fondamentale des temps locaux]
Soit $Y$ une semi-martingale et $L$ la fonction de ses temps locaux. Pour tout $y \in \R$, la mesure aléatoire $dL^y_t$ est portée par ${t \geq 0 : Y_t = y}$.  
\end{prop}

\begin{remark}
  Dans d'autres mots, si on se donne $X$ une semi-martingale, alors  $L_t^x(X)$ est constante pour tout $X_t \neq x$.
\end{remark}

\section{Formule de Tanaka}

{\color{red}
  \begin{theorem}[Formule de Tanaka]
  \end{theorem}
    
  \begin{theorem}[Formule d'Itō-Tanaka]
  \end{theorem}
}
\section{Formule d'Occupation}

\begin{theorem}[Formule d'occupation]
\label{thm:occupation}
Soit $X_t$ une semimartingale continue de variation quadratique $[X]_t$. Alors, il existe un processus mesurable $(L_t^a)_{t\geq0}$, tel que p.s. pour toute fonction borelienne bornée $\varphi : \R \mapsto \R$ :

\begin{equation}
  \int_0^t \varphi(X_s) ds = \int_{\R_+}\varphi(a)L_t^a(X)da
\end{equation}

\end{theorem}

{\color{red}\begin{proof}
  \end{proof}}

La formule d'occupation est très utile puisqu'elle nous permet de relier le temps qu’un processus stochastique passe dans un certain ensemble à des propriétés locales de ce processus.

L'une des conséquences de la formule d'occupation est la suivante :

\begin{prop}[Temps local de la fonction d'une semi-martingale]
  Soient $f$ convexe et $X$ une semi-martingale. Alors,
  $$L_t^{(f(a)}f(X)) = f'(a) L^a(X)$$
\end{prop}

\begin{remark}
  Si $f$ n'est pas une fonction convexe, mais la différence (ou la somme) de fonctions convexes, alors on peut quand même appliquer la formule d'Itō par linéarité de l'intégrale!
\end{remark}

\begin{proof}
  Soient $Y_t = f(X_t)$ et $X_t = M_t + V_t$ une semi-martingale. Montrons en premier, que $Y_t$ est une semi-martingale. 
  \begin{alignat*}{1}
    Y_t &\overset{\text{Itō}}{=} f(X_0) + \int_0^t f'(X_s) dX_s + \int_0^t f''(X_s) d[X]_s\\
        &= \underbrace{f(X_0)}_{\F_0\text{-mesurable}} + \underbrace{\int_0^t f'(X_s) dM_s}_{\text{Intégrale stochastique}} + \underbrace{\int_0^t f'(X_s) dV_s}_{\text{Processus v.f.}} + \underbrace{\int_0^t f''(X_s) d[M]_s}_{\text{Processus v.f.}}
  \end{alignat*}
  Comme $f'(X_s)$ est $\F_s$-mesurable pour tout $s<t$, alors, c'est un processus prévisible et $\int_0^t f'(X_s) dM_s$ est une martingale.
  Donc on peut décomposer $Y_t$ dans la somme d'une martingale et d'un processus à variation finie, c'est donc une semi-martingale.


  
Maintenant qu'on sait que $Y_t$ est une semimartingale, on peut appliquer la formule d'occupation (\autoref{thm:occupation}). Soit $\varphi$ une fonction borélienne bornée. Remarquons d'abord que $d[Y]_s = \left(f'(X_s)\right)^2 d[M]_s$. On a donc :
$$  \int_0^t \varphi(Y_s) d[Y]_s \overset{\text{def}}{=} \int_0^t \underbrace{\varphi(f(X_s)) \left(f'(X_s\right)^2)}_{\tilde\varphi(X_s)} d[X_s]
$$

On applique la formule d'occupation au RHS et LHS respectivement.
\begin{alignat*}{1}
%  \int_0^t \varphi(Y_s) d[Y]_s &\overset{\text{def}}{=} \int_0^t \underbrace{\varphi(f(X_s)) \left(f'(X_s\right)^2)}_{\tilde\varphi(X_s)} d[X_s]
%\intertext{On applique la formule d'occupation au RHS et LHS respectivement.}
\int_{\R_+} \varphi(y) L_t^y(Y) dy &= \int_{\R_+} \tilde\varphi(x) L_t^x(X) dx\\
                         &= \int_{\R_+}\varphi(f(x)) \left(f'(x)\right)^2 L_t^x(X) dx\\
                      &\overset{y = f^{-1}(x)}{=} \int_{\R_+}\varphi(y) f'( (f^{-1}(y))^2) L_t^{f^{-1}(y)}(f^{-1}(Y)) \; \frac{1}{f'(f^{-1}(y))} dy.\\
\end{alignat*}

Par linéarité de l'intégrale, 
$$\int_{\R_+} \varphi(y) \left( L_t^y(Y) -  f'\left((f^{-1}(y))^2\right) L_t^{f^{-1}(y)}(f^{-1}(Y)) \; \frac{1}{f'(f^{-1}(y))}\right) dy  = 0 $$

est vrai pour toute fonction $\varphi$, borélienne bornée, alors, en renplaçant $y$ par $f(x)$, peut dire que p.s :

$$L_t^{f(x)}(f(X)) =  f'(x) L_t^{x}(X).$$
\end{proof}

\chapter{Processus de Bessel}
\section{construction d'un bessel avec un mvt brownien}
\section{Carré de Bessel}
\subsection{Définition informelle}
\subsection{Formule d'occupation pour un processus de Bessel}
\end{document}